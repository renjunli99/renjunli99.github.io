<!DOCTYPE HTML>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Junli Ren</title>

    <meta name="author" content="Junli Ren">
    <!-- <meta name="viewport" content="width=device-width, initial-scale=1"> -->

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" type="image/x-icon" href="images/Personal/ico.jpeg">

</head>

<body>
    <table
        style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr style="padding:0px">
                <td style="padding:0px">
                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr style="padding:0px">
                                <td style="padding:2.0%;width:60%;vertical-align:middle">
                                    <p> Hello there! I am a first-year PHD student in HKU(the University of HongKong), advised by <a href="http://luoping.me/" target="_blank">Prof. Ping Luo</a>. 
                                        I am currently intern in Shanghai AI Lab, supervised by <a href="https://oceanpang.github.io/" target="_blank">Dr. Jiangmiao Pang</a>.
                                        I obtained my Master and B.Eng. degree in Tsinghua University, unders the supervision of Prof  <a href="http://web.ee.tsinghua.edu.cn/wangguijin/en/index.htm" target="_blank">Prof. Guijin Wang</a>. 
                                    </p>
                                    <p> I am currently working on humanoid robots and reinforcement learning. If you are interested in my research or want to chat, please drop me an <a href="mailto:junlir@connect.hku.hk">email</a>. 
                                    </p>
                                </td>
                                <td style="padding:6.0%;width:40%;vertical-align:middle">
                                    <a href="images/Personal/wukong.jpg"><img style="width:100%;max-width:100%"
                                            alt="profile photo" src="images/Personal/wukong.jpg" class="hoverZoomLink"></a>
                                    <p style="text-align:center">
                                        <name> Junli Ren「任峻立」</name>
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    
                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <heading>Selected Publications</heading>
                                </td>
                            </tr>
                        </tbody>
                    </table>


                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one" >
                                        <img src="pubs/2025.VBCOM/vbcom.gif" style="width:100%;max-width:100%; position: absolute;top: 0%">
                                    </div>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <papertitle>VB-Com: Learning Vision-Blind Composite Humanoid Locomotion Against Deficient Perception</papertitle>
                                    <br>
                                    <br>
                                    <strong>Junli Ren</strong>, Tao Huang, Huayi Wang, Zirui Wang, Qingwei Ben, Jiangmiao Pang†, Ping Luo†
                                    <br>
                                    <br>
                                    <em> Preprint </em>
                                    <br>
                                    <br>
                                    <a href="https://renjunli99.github.io/vbcom.github.io/" target="_blank">[Project Page]</a>
                                    <a href="https://arxiv.org/abs/2502.14814" target="_blank">[Paper]</a>
                                    <a href="https://youtu.be/f9iUE3v7I-8" target="_blank">[Video]</a>
                                    <a href="pubs/2025.VBCOM/bibtex.txt" target="_blank">[BibTeX]</a>
                                    <br>
                                    <p> We propose VB-Com, a composite framework that enables humanoid robots to determine when to rely on the vision policy and when to switch to the blind policy under perceptual deficiency. </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one" >
                                        <img src="pubs/2025.HOST/host.gif" style="width:100%;max-width:100%; position: absolute;top: 0%">
                                    </div>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <papertitle>Learning Humanoid Standing-up Control across Diverse Postures</papertitle>
                                    <br>
                                    <br>
                                    Tao Huang, <strong>Junli Ren</strong>, Huayi Wang, Zirui Wang, Qingwei Ben, Muning Wen, Xiao Chen, Jianan Li, Jiangmiao Pang†
                                    <br>
                                    <br>
                                    <em> Preprint </em>
                                    <br>
                                    <br>
                                    <a href="https://taohuang13.github.io/humanoid-standingup.github.io/" target="_blank">[Project Page]</a>
                                    <a href="https://arxiv.org/pdf/2502.08378" target="_blank">[Paper]</a>
                                    <a href="https://www.youtube.com/watch?v=Yruh-3CFwE4&amp;source_ve_path=OTY3MTQ" target="_blank">[Video]</a>
                                    <a href="pubs/2025.HOST/bibtex.txt" target="_blank">[BibTeX]</a>
                                    <br>
                                    <p> we present HoST (Humanoid Standing-up Control), a reinforcement learning framework that learns standing-up control from scratch, enabling robust sim-to-real transfer across diverse postures.</p>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one" >
                                        <img src="pubs/2025.Beamdojo/beamdojo.gif" style="width:100%;max-width:100%; position: absolute;top: 0%">
                                    </div>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <papertitle>BeamDojo: Learning Agile Humanoid Locomotion on Sparse Footholds</papertitle>
                                    <br>
                                    <br>
                                    Huayi Wang, Zirui Wang, <strong>Junli Ren</strong>, Qingwei Ben, Tao Huang, Weinan Zhang, Jiangmiao Pang†
                                    <br>
                                    <br>
                                    <em> Preprint </em>
                                    <br>
                                    <br>
                                    <a href="https://why618188.github.io/beamdojo/" target="_blank">[Project Page]</a>
                                    <a href="https://arxiv.org/abs/2502.10363" target="_blank">[Paper]</a>
                                    <a href="https://www.youtube.com/watch?v=ZiiIZaXXkKE&amp;feature=youtu.be" target="_blank">[Video]</a>
                                    <a href="pubs/2025.Beamdojo/bibtex.txt" target="_blank">[BibTeX]</a>
                                    <br>
                                    <p> BeamDojo achieves efficient learning in simulation and enables agile locomotion with precise foot placement on sparse footholds in the real world, 
                                        maintaining a high success rate even under significant external disturbances.</p>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one" >
                                        <img src="pubs/2024.PIM/pim.gif" style="width:100%;max-width:100%; position: absolute;top: 0%">
                                    </div>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <papertitle>Learning Humanoid Locomotion with Perceptive Internal Model</papertitle>
                                    <br>
                                    <br>
                                    Junfeng Long*, <strong>Junli Ren*</strong>, Moji Shi*, Zirui Wang, Tao Huang, Ping Luo, Jiangmiao Pang†
                                    <br>
                                    <br>
                                    <em> International Conference on Robotics and Automation (ICRA), 2025</em>
                                    <br>
                                    <br>
                                    <a href="https://junfeng-long.github.io/PIM/" target="_blank">[Project Page]</a>
                                    <a href="https://arxiv.org/abs/2411.14386" target="_blank">[Paper]</a>
                                    <a href="https://github.com/OpenRobotLab/HIMLoco" target="_blank">[Code]</a>
                                    <a href="pubs/2024.PIM/bibtex.txt" target="_blank">[BibTeX]</a>
                                    <br>
                                    <p> We propose the Perceptive Intenal Model (PIM), a method to estimate environmental disturbances
                                        with perceptive information, enabling agile and robust locomotion for various humanoid robots on various terrains.</p>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one" >
                                        <img src="pubs/2024.TOP-Nav/topnavsnow.gif" style="width:100%;max-width:100%; position: absolute;top: 0%">
                                    </div>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <papertitle>TOP-Nav: Legged Navigation Integrating Terrain, Obstacle and Proprioception Estimation</papertitle>
                                    <br>
                                    <br>
                                    <strong>Junli Ren*</strong>, Yikai Liu*, Yingru Dai, Junfeng Long, Guijin Wang†
                                    <br>
                                    <br>
                                    <em>Conference on Robot Learning (CoRL), 2024</em>
                                    <br>
                                    <br>
                                    <a href="https://top-nav-legged.github.io/TOP-Nav-Legged-page/" target="_blank">[Project Page]</a>
                                    <a href="https://arxiv.org/abs/2404.15256" target="_blank">[Paper]</a>
                                    <a href="https://github.com/TOP-Nav-Legged/TOP-Nav-Legged" target="_blank">[Code]</a>
                                    <a href="pubs/2024.TOP-Nav/bibtex.txt" target="_blank">[BibTeX]</a>
                                    <br>
                                    <p>  We propose TOP-Nav, a novel legged navigation framework that integrates a comprehensive path planner 
                                         with Terrain awareness, Obstacle avoidance and close-loop Proprioception.</p>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                        <tr>
                          <td style="padding:0px">
                            <br>
                            <p style="text-align:right;font-size:normal;">
                            Updated at Feb. 2025.
                            <br>
                            Template from <a href="https://jonbarron.info/" style="text-align:right;font-size:normal;" target="_blank">Jon Barron</a>. 
                            </p>
                          </td>
                        </tr>
                      </tbody>
                    </table>

                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                        <tr>
                          <td style="padding:0px">
                            <br>
                            <div style="text-align: right;">
                                <a href="https://hits.seeyoufarm.com"><img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Frenjunli99.github.io&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false"/></a>

                            </div>
                        </tr>
                        </tbody>
                    </table>


                </td>
            </tr>
        </tbody>
        
    </table>

   

   
</body>

</html>
